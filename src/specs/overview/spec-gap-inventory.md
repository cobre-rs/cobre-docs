# Spec Gap Inventory

## 1. Purpose

This document catalogs every specification gap that would block, delay, or compromise the implementation of the minimal viable SDDP solver as defined in [Implementation Ordering](./implementation-ordering.md). Each gap identifies missing information, ambiguous behavior, undefined interfaces, or underspecified edge cases across the eight required crates (cobre-core, cobre-io, cobre-stochastic, cobre-solver, cobre-sddp, cobre-comm, cobre-cli, ferrompi). The inventory is the starting point for a targeted resolution effort prior to and during coding.

## 2. Scope and Classification

**Scope.** This inventory covers only the minimal viable solver: the eight crates listed in [Implementation Ordering](./implementation-ordering.md) section 4, the four fully-modeled system element types (Bus, Line, Thermal, Hydro), constant hydro productivity, single-cut formulation, Expectation risk measure, Level-1 cut selection, Finite horizon mode, InSample sampling scheme, all five stopping rules, HiGHS solver backend, and MPI communicator backend. Deferred features (Python bindings, TUI, MCP server, TCP/shm backends, CVaR, Cyclic horizon, LML1, External/Historical sampling, CLP solver, multi-cut, FPHA, GNL, batteries, non-convex simulation extensions, complete tree mode) are explicitly out of scope and are NOT flagged as gaps.

**Architectural hooks.** While deferred features themselves are not gaps, architectural hooks that enable future addition of deferred features ARE evaluated. If a hook is underspecified in a way that could force a breaking change when the feature is added, it is logged.

**Severity levels.**

| Severity | Definition                                                                                                                                   | Action Required       |
| -------- | -------------------------------------------------------------------------------------------------------------------------------------------- | --------------------- |
| Blocker  | Cannot proceed without resolving. Missing information, contradictions, or undefined interfaces that prevent writing correct code.            | Before coding starts  |
| High     | Can start but blocked before completion. Ambiguous behavior, missing edge cases, or incomplete type definitions that will block integration. | During implementation |
| Medium   | Can complete but may be incorrect or suboptimal. Missing performance constraints, unclear defaults, or unspecified recovery behavior.        | During implementation |
| Low      | Can complete correctly. Missing documentation, unclear rationale, or cosmetic issues that do not affect correctness.                         | Opportunistically     |

## 3. Gap Inventory Table

| ID      | Severity | Affected Crate(s)            | Spec File(s)                                                                                                                     | Section(s)          | Description                                                                                                                                                                                                                                                                                                                                                                                                                                    | Resolution Path                                                                                                                                                                                                                                                                                                                                                                                                         |
| ------- | -------- | ---------------------------- | -------------------------------------------------------------------------------------------------------------------------------- | ------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| GAP-001 | Blocker  | cobre-core, cobre-sddp       | [Internal Structures](../data-model/internal-structures.md)                                                                      | 1, 2                | **Resolved.** The `SystemRepresentation` top-level type that holds all entity collections, metadata, and cascade topology is described only narratively. No struct sketch, no public API surface, and no method signatures for querying entities by ID or iterating in canonical order. All downstream crates depend on this type.                                                                                                             | **Resolved** -- `SystemRepresentation` struct sketch defined in [Internal Structures](../data-model/internal-structures.md) SS1.1--1.7, with public accessors, entity-count queries, cascade topology lookup, and `Send + Sync` bounds.                                                                                                                                                                                 |
| GAP-002 | Blocker  | cobre-core, cobre-sddp       | [Internal Structures](../data-model/internal-structures.md), [LP Formulation](../math/lp-formulation.md)                         | 2, 3                | **Resolved.** The operative state machine (Non-existing, Filling, Operating, Decommissioned) is defined but the Decommissioned state references an "open question" in [Input System Entities](../data-model/input-system-entities.md) section 3. The LP treatment of Decommissioned entities is undefined -- does it match Non-existing (zero variables), or does it have residual constraints (e.g., reservoir drainage)?                     | **Resolved** -- Decommissioned is treated identically to Non-existing (zero variables, zero constraints), documented in [Internal Structures](../data-model/internal-structures.md) SS2. Open question closed.                                                                                                                                                                                                          |
| GAP-003 | Blocker  | cobre-io, cobre-core         | [Input Loading Pipeline](../architecture/input-loading-pipeline.md)                                                              | 6                   | **Resolved.** The broadcast strategy states data is "serialized to contiguous byte buffers for MPI broadcast" but does not specify the serialization format. Is this `bincode`, `rkyv`, `postcard`, manual `unsafe` transmute of `#[repr(C)]` types, or something else? The choice affects cobre-core type design (must be serializable) and cobre-io implementation.                                                                          | **Resolved** -- `rkyv` zero-copy serialization adopted for MPI broadcast, documented in [Input Loading Pipeline](../architecture/input-loading-pipeline.md) SS6.1--6.4. `Archive + Serialize + Deserialize` bounds added to cobre-core types.                                                                                                                                                                           |
| GAP-004 | Blocker  | cobre-sddp, cobre-solver     | [Solver Abstraction](../architecture/solver-abstraction.md), [Solver Interface Trait](../architecture/solver-interface-trait.md) | 3, 4.4              | The `StageTemplate` struct is defined in the solver interface trait but the construction process (how cobre-sddp builds a `StageTemplate` from `InternalStructures` + `StageDefinition`) is not specified. This is the bridge between the data model and the LP solver. Which crate owns this construction? What is the public API?                                                                                                            | Specify that cobre-sddp owns `StageTemplate` construction. Define a builder function signature: `fn build_stage_template(system: &System, stage: &Stage, config: &ModelingConfig) -> StageTemplate`. Document the column/row index mapping from entity IDs to LP positions.                                                                                                                                             |
| GAP-005 | Blocker  | cobre-sddp                   | [Training Loop](../architecture/training-loop.md), [Solver Abstraction](../architecture/solver-abstraction.md)                   | 4.2, 11.2           | The forward pass step "Build stage LP" (step c) references building the LP with "incoming state, scenario realization, and all current FCF cuts" but the exact sequence of `patch_rhs_bounds` calls is unspecified. How many patches per stage? Which constraint indices receive which values (storage RHS, AR lag fixing, noise fixing)? The LP layout convention defines regions but not the exact index arithmetic.                         | Specify the patch list: for each state variable type, give the row index formula (relative to stage template) and the patch value source. Provide a worked example for a 3-hydro, AR(2) system.                                                                                                                                                                                                                         |
| GAP-006 | High     | cobre-sddp                   | [Training Loop](../architecture/training-loop.md)                                                                                | 5.2, 6.1            | The forward pass collects visited states across all ranks via `allgatherv` (section 5.2 step 3), but the exact wire format for state vectors is unspecified. Is it a flat `[f64]` with implicit indexing (scenario-major or stage-major)? How are counts and displacements computed from per-rank scenario assignments?                                                                                                                        | Define the wire format: `[f64; n_state]` per visited state per scenario, concatenated scenario-major. Specify counts as `per_rank_scenarios * n_state` and displacements as cumulative sums.                                                                                                                                                                                                                            |
| GAP-007 | High     | cobre-sddp                   | [Cut Management Implementation](../architecture/cut-management-impl.md)                                                          | 4.2                 | The MPI wire format for cut synchronization is specified per-cut (slot index, iteration, forward pass index, intercept, coefficients) but the endianness convention, alignment requirements, and whether this is a raw byte reinterpretation or a structured serialization are unspecified.                                                                                                                                                    | Specify native endianness (same architecture assumed within an MPI job), 8-byte alignment, and raw `[u8]` reinterpretation of `#[repr(C)]` packed structs. Document the assumption that all ranks in an MPI job share the same architecture.                                                                                                                                                                            |
| GAP-008 | High     | cobre-sddp                   | [Training Loop](../architecture/training-loop.md)                                                                                | 7.2                 | Cut coefficient computation references "AR lag fixing constraints" whose duals are extracted, but the AR lag fixing constraints are not defined in [LP Formulation](../math/lp-formulation.md). The LP formulation shows the AR dynamics equation but not the separate fixing constraints that bind lag variables to incoming state values. These constraints and their LP row positions must be specified for correct dual extraction.        | Add the AR lag fixing constraints to the LP formulation: one equality constraint per (hydro, lag) that binds the lag variable to the incoming state value. Assign these constraints to the cut-relevant top region of the row layout.                                                                                                                                                                                   |
| GAP-009 | High     | cobre-solver                 | [Solver Interface Trait](../architecture/solver-interface-trait.md)                                                              | 2.3                 | `patch_rhs_bounds` accepts `&[(usize, f64)]` but the semantics are ambiguous: does the `usize` index refer to row indices (for RHS patching) or column indices (for bound patching)? The method description says "RHS values and variable bounds" but the signature has a single flat array. HiGHS uses separate APIs for row bounds and column bounds.                                                                                        | Split into two methods: `patch_row_bounds(&mut self, patches: &[(usize, f64, f64)])` for row lower/upper and `patch_col_bounds(&mut self, patches: &[(usize, f64, f64)])` for column lower/upper. Alternatively, use a tagged union. Document the mapping to HiGHS `changeRowsBoundsBySet` and `changeColsBoundsBySet`.                                                                                                 |
| GAP-010 | High     | cobre-sddp, cobre-solver     | [Solver Abstraction](../architecture/solver-abstraction.md)                                                                      | 3, open point       | The LP scaling strategy is explicitly deferred as an "open point." For the minimal viable solver, is single-phase scaling adopted as the baseline, or is no scaling applied? If no scaling, the risk of numerical difficulties on production-scale problems is elevated.                                                                                                                                                                       | Adopt single-phase scaling as the baseline for the minimal viable solver. Document the decision. Defer two-phase scaling to a later optimization pass.                                                                                                                                                                                                                                                                  |
| GAP-011 | High     | cobre-sddp, cobre-solver     | [Solver Abstraction](../architecture/solver-abstraction.md)                                                                      | 5.4, open question  | The "selective vs bulk cut loading" strategy is explicitly deferred as an "open question." The current baseline (selective addition) is described but not formally adopted. This affects `CutBatch` assembly logic and solver configuration (presolve on/off).                                                                                                                                                                                 | Formally adopt selective addition as the baseline. Remove the open question marker. Document that bulk loading with bound deactivation is a deferred optimization.                                                                                                                                                                                                                                                      |
| GAP-012 | High     | cobre-core, cobre-io         | [Input Loading Pipeline](../architecture/input-loading-pipeline.md), [Internal Structures](../data-model/internal-structures.md) | 8, 1                | The "transition to in-memory model" section states that the in-memory structures are "not specified here" and defers to Internal Structures, which in turn describes the logical model without implementation types. The actual Rust struct definitions that cobre-io produces and cobre-core holds are undefined. Neither spec provides the concrete type that crosses the crate boundary.                                                    | Define the public API: `cobre_io::load_case(path: &Path) -> Result<cobre_core::System, LoadError>`. Specify the `System` type as the concrete struct that holds all resolved internal structures. This is the primary crate boundary contract between cobre-io and cobre-core.                                                                                                                                          |
| GAP-013 | High     | cobre-sddp                   | [Training Loop](../architecture/training-loop.md)                                                                                | 2.1a                | Event types (`ForwardPassComplete`, `BackwardPassComplete`, `ConvergenceUpdate`, etc.) are listed with payload summaries but no Rust type definitions are provided. The spec says "Event types are defined in `cobre-core`" but no event enum or struct definitions appear in any cobre-core spec.                                                                                                                                             | Define a `TrainingEvent` enum in cobre-core with one variant per event type and typed payload structs. These are needed for the convergence monitoring, logging, and future TUI/MCP integration hooks.                                                                                                                                                                                                                  |
| GAP-014 | High     | cobre-stochastic, cobre-sddp | [Scenario Generation](../architecture/scenario-generation.md)                                                                    | 2.2                 | Reproducible sampling requires a "deterministic hash function" to derive per-(iteration, scenario, stage) seeds from a base seed, but the hash function is not specified. The choice of hash function affects reproducibility guarantees across platforms and Rust compiler versions.                                                                                                                                                          | Specify a concrete hash function (e.g., `SipHash-2-4` from `std::collections::hash_map::DefaultHasher`, or `xxhash` for speed). Define the exact input format: `hash(base_seed, iteration, scenario, stage)` with fixed-width integer encoding.                                                                                                                                                                         |
| GAP-015 | High     | cobre-sddp                   | [Convergence Monitoring](../architecture/convergence-monitoring.md)                                                              | 1                   | The simulation-based stopping rule (section 2.3 step 4) requires running Monte Carlo simulations during training to assess policy stability, but the interaction with the main training loop is underspecified. Does the simulation reuse the training LP infrastructure? Does it block the training loop? How many threads does it consume? Where do the simulation scenarios come from?                                                      | Specify that the simulation-based stopping rule reuses the forward pass infrastructure with a dedicated scenario set. Clarify that it runs synchronously (blocks the iteration) on the check period. Document the scenario source (fresh InSample draws with a separate seed).                                                                                                                                          |
| GAP-016 | High     | cobre-cli                    | [CLI and Lifecycle](../architecture/cli-and-lifecycle.md)                                                                        | not found           | The CLI spec is referenced in the implementation ordering but was not included in the reading list for this ticket. The spec file exists but key details about the `run` subcommand's interaction with MPI initialization, config resolution order, and the exact phase boundaries (which phases are rank-0 only, which are all-ranks) must be verified against the training loop spec.                                                        | Audit [CLI and Lifecycle](../architecture/cli-and-lifecycle.md) for consistency with [Training Loop](../architecture/training-loop.md) phase boundaries. Ensure MPI init happens before config loading and that rank-0 validation is explicitly sequenced.                                                                                                                                                              |
| GAP-017 | High     | ferrompi                     | [Hybrid Parallelism](../hpc/hybrid-parallelism.md), [Backend: Ferrompi](../hpc/backend-ferrompi.md)                              | 2.1                 | The ferrompi crate API surface is described indirectly through the `FerrompiBackend` wrapper but the ferrompi crate itself has no standalone API specification. Methods like `init_with_threading`, `allgatherv`, `allreduce`, `bcast`, `barrier`, `SharedWindow::new`, `SharedWindow::as_slice`, `SharedWindow::fence` are referenced but their exact Rust signatures, error types, and `unsafe` boundaries are unspecified.                  | Create a ferrompi API reference spec (or section in the ferrompi crate doc) that defines each public method's signature, preconditions, postconditions, and error types. This is the contract that the cobre-comm ferrompi backend implements against.                                                                                                                                                                  |
| GAP-018 | Medium   | cobre-sddp                   | [Training Loop](../architecture/training-loop.md)                                                                                | 4.3                 | The "thread-trajectory affinity" pattern for the forward pass states that each OpenMP thread owns complete trajectories, but the OpenMP integration strategy for Rust is unspecified. Rust does not natively support OpenMP. Will this use `rayon`, `std::thread` with manual affinity, or FFI to OpenMP via C? The parallelism model affects every performance-critical code path.                                                            | Specify the threading model: recommend `rayon` with a custom thread pool sized to match NUMA topology, or `std::thread::scope` with explicit pinning. Document the decision and its implications for work-stealing vs. static partitioning.                                                                                                                                                                             |
| GAP-019 | Medium   | cobre-sddp                   | [Solver Abstraction](../architecture/solver-abstraction.md)                                                                      | 7.1                 | The retry logic contract specifies "maximum attempts: 5" and "time budget" as defaults, but no configuration parameters for these appear in [Configuration Reference](../configuration/configuration-reference.md). The retry policy is hardcoded behavior with no user override path.                                                                                                                                                         | Add `solver.retry_max_attempts` and `solver.retry_time_budget_seconds` to the configuration reference. Alternatively, document that these are implementation-internal constants not exposed to users.                                                                                                                                                                                                                   |
| GAP-020 | Medium   | cobre-io                     | [Output Schemas](../data-model/output-schemas.md), [Output Infrastructure](../data-model/output-infrastructure.md)               | 1                   | The output directory structure and Parquet schemas are well-defined, but the API for writing output from cobre-sddp is unspecified. Does cobre-sddp call cobre-io functions directly? Is there a writer trait? What is the function signature for streaming simulation results? The crate boundary between cobre-sddp (producer) and cobre-io (writer) needs an explicit interface.                                                            | Define a `SimulationWriter` trait or concrete type in cobre-io with methods like `write_scenario_result(&mut self, scenario_id: u32, results: &ScenarioResult) -> Result<(), IoError>`. Specify thread-safety requirements (the writer is accessed from the I/O background thread).                                                                                                                                     |
| GAP-021 | Medium   | cobre-io                     | [Binary Formats](../data-model/binary-formats.md)                                                                                | 3                   | The FlatBuffers schema for cut persistence is referenced but not provided in full. The spec describes the schema conceptually (StageCuts, BendersCut, StageBasis) but the actual `.fbs` schema file that would be used for code generation is not included.                                                                                                                                                                                    | Include the complete FlatBuffers `.fbs` schema definition in the spec, or create a dedicated schema file referenced from the spec. This is needed for `flatc` code generation during implementation.                                                                                                                                                                                                                    |
| GAP-022 | Medium   | cobre-stochastic             | [Scenario Generation](../architecture/scenario-generation.md)                                                                    | 1.2, 1.3            | The PAR preprocessing pipeline produces contiguous arrays (`base`, `coefficients`, `scales`, `orders`) but the concrete Rust types that hold these arrays are unspecified. Is this a single struct? Multiple arrays? Does it own the data or borrow from cobre-core? This is the primary data structure that cobre-stochastic exposes to cobre-sddp.                                                                                           | Define a `PrecomputedPar` struct with owned contiguous arrays. Specify the public constructor `fn precompute_par(system: &System, stages: &[Stage]) -> PrecomputedPar` and the runtime evaluation method `fn evaluate(&self, stage: usize, hydro: usize, lags: &[f64], noise: f64) -> f64`.                                                                                                                             |
| GAP-023 | Medium   | cobre-stochastic, cobre-sddp | [Scenario Generation](../architecture/scenario-generation.md)                                                                    | 2.3                 | The opening tree is described as a 3D array `(T x N_openings x N_entities)` stored in opening-major order, but the Rust type and ownership model are unspecified. Is this a `Vec<f64>` with manual indexing? An `ndarray::Array3`? A `SharedRegion<f64>` from cobre-comm? The type crosses the cobre-stochastic/cobre-sddp boundary.                                                                                                           | Define the opening tree type: recommend a flat `Vec<f64>` with an accessor struct that provides `fn noise(&self, opening: usize, stage: usize, entity: usize) -> f64` with bounds-checked indexing. Specify that the tree is allocated once and shared read-only via `Arc` or `SharedRegion`.                                                                                                                           |
| GAP-024 | Medium   | cobre-sddp                   | [Cut Management Implementation](../architecture/cut-management-impl.md)                                                          | 6.1                 | Cut activity tracking requires detecting which cuts are "binding" after each LP solve by checking if the cut's dual multiplier is positive. The tolerance for "positive" is described as "configurable" but no default value or configuration parameter is specified.                                                                                                                                                                          | Add a `cut_activity_tolerance` parameter to the configuration reference with a default of `1e-6`. Document that this tolerance determines whether a cut is considered binding for Level-1 selection.                                                                                                                                                                                                                    |
| GAP-025 | Medium   | cobre-core, cobre-sddp       | [Penalty System](../data-model/penalty-system.md), [LP Formulation](../math/lp-formulation.md)                                   | 2, 1.5              | The penalty priority ordering is specified qualitatively but no quantitative validation rule exists. A user could set `deficit_cost < spillage_cost`, violating the ordering. Should the loader warn, error, or silently accept? The spec says the ordering "must be maintained" but does not specify enforcement.                                                                                                                             | Add a validation rule in the input loading pipeline that checks penalty priority ordering and emits a warning (not error) if violated. Document that violations may cause suboptimal policy behavior but do not break algorithmic correctness.                                                                                                                                                                          |
| GAP-026 | Medium   | cobre-sddp                   | [Training Loop](../architecture/training-loop.md)                                                                                | 6.3                 | The backward pass states "trial states at each stage are distributed across MPI ranks" but the distribution strategy is not specified. Is it contiguous block assignment (like forward scenarios) or round-robin? When the number of trial states differs from the number of forward passes (e.g., after deduplication in future), how is load balancing handled?                                                                              | Specify contiguous block assignment for backward trial state distribution, consistent with the forward pass pattern. Document that all ranks receive the same set of trial states via `allgatherv` and each rank processes its assigned subset.                                                                                                                                                                         |
| GAP-027 | Medium   | cobre-cli, cobre-sddp        | [Configuration Reference](../configuration/configuration-reference.md)                                                           | 3.1                 | The `training.forward_passes` parameter has no documented default value (the table shows "---"). This is a mandatory parameter for the training loop. Should the loader reject configs without it, or should there be a sensible default?                                                                                                                                                                                                      | Specify that `training.forward_passes` is required (no default) and the loader emits an error if it is missing. Alternatively, define a default based on MPI rank count (e.g., `max(1, n_ranks)`).                                                                                                                                                                                                                      |
| GAP-028 | Medium   | cobre-sddp                   | [Simulation Architecture](../architecture/simulation-architecture.md)                                                            | 2                   | Policy compatibility validation is described as a "hard error" on mismatch, but the full validation specification is deferred to [Deferred Features SSC.9](../deferred.md). For the minimal viable solver, where training and simulation run in the same execution, is policy compatibility validation still needed? If warm-start is supported, it is needed.                                                                                 | Clarify scope: if warm-start is in the minimal viable (it is, per implementation ordering Phase 7), define the minimal set of compatibility checks inline (state dimension, hydro count, AR orders). Defer the full validation algorithm but implement the minimal checks.                                                                                                                                              |
| GAP-029 | Medium   | cobre-io                     | [Input Loading Pipeline](../architecture/input-loading-pipeline.md)                                                              | 2.6                 | Cross-reference validation lists specific checks but notes the list is "illustrative, not exhaustive." For implementation, the developer needs a complete, enumerated list of cross-reference checks.                                                                                                                                                                                                                                          | Enumerate all required cross-reference validations as a checklist. Reference the existing checks in sections 2.1-2.5 and add any missing ones (e.g., cascade cycle detection, deficit segment unbounded final tier).                                                                                                                                                                                                    |
| GAP-030 | Medium   | cobre-sddp                   | [Training Loop](../architecture/training-loop.md)                                                                                | 4.2                 | The forward pass step "Record" (step e) says to store "the stage cost and the end-of-stage state" but does not specify the data structure for per-scenario trajectory records. Is this a flat array? A struct per stage? How is it indexed for the backward pass?                                                                                                                                                                              | Define a `TrajectoryRecord` type that holds per-stage state vectors and costs for one forward scenario. Specify storage as a contiguous buffer indexed by `[scenario][stage]` for cache-friendly backward pass access.                                                                                                                                                                                                  |
| GAP-031 | Low      | cobre-core                   | [Internal Structures](../data-model/internal-structures.md)                                                                      | 12                  | The `Stage` definition lists fields `num_scenarios` and `sampling_method` that appear to be scenario generation parameters, not stage structural properties. These overlap with the `scenario_source` configuration in `stages.json`. The relationship and deduplication between these fields is unclear.                                                                                                                                      | Clarify that `num_scenarios` maps to `n_openings` from `stages.json` and `sampling_method` is a legacy field replaced by `scenario_source.sampling_scheme`. Remove or deprecate the ambiguous fields.                                                                                                                                                                                                                   |
| GAP-032 | Low      | cobre-sddp                   | [Training Loop](../architecture/training-loop.md)                                                                                | 2.1a                | The event channel uses `Option<broadcast::Sender<TrainingEvent>>` but `broadcast` is not a standard library type. This appears to reference `tokio::sync::broadcast` which implies an async runtime dependency. For a synchronous MPI binary, this is architecturally significant.                                                                                                                                                             | Clarify the event channel implementation: recommend `crossbeam::channel` or `std::sync::mpsc` for the synchronous CLI binary. Reserve `tokio::sync::broadcast` for the async Python/MCP interfaces (deferred crates).                                                                                                                                                                                                   |
| GAP-033 | Low      | cobre-comm                   | [Communicator Trait](../hpc/communicator-trait.md)                                                                               | 4.5                 | The `train` function signature shows `C: Communicator + SharedMemoryProvider` as the generic bound, but the solver interface trait shows `C: Communicator` only (without `SharedMemoryProvider`). The exact set of generic bounds on the training entry point is inconsistent between the two specs.                                                                                                                                           | Unify: the training entry point should require `C: Communicator + SharedMemoryProvider` since shared memory is used for the opening tree and case data. Update the solver interface trait example to match.                                                                                                                                                                                                             |
| GAP-034 | Low      | cobre-sddp                   | [Cut Management Implementation](../architecture/cut-management-impl.md)                                                          | 1.3                 | The cut pool capacity formula `warm_start_cuts + max_iterations x forward_passes` assumes a fixed `forward_passes_per_iteration` value. If the configuration allows dynamic adjustment of forward pass count, the preallocation would be invalid. The spec should confirm that `forward_passes` is fixed for the entire run.                                                                                                                   | Confirm that `forward_passes` is immutable after initialization. Document this as a precondition of the deterministic slot assignment formula.                                                                                                                                                                                                                                                                          |
| GAP-035 | Low      | all 8 crates                 | [Configuration Reference](../configuration/configuration-reference.md)                                                           | 7                   | The complete example `config.json` includes `"method": "domination"` for cut selection, but the minimal viable solver uses Level-1 (per implementation ordering section 6). The example should reflect the minimal viable defaults to avoid confusion.                                                                                                                                                                                         | Update the example to use `"method": "level1"` and `"risk_measure": "expectation"` to match the minimal viable configuration.                                                                                                                                                                                                                                                                                           |
| GAP-036 | High     | cobre-sddp, cobre-solver     | [Solver Workspaces](../architecture/solver-workspaces.md)                                                                        | not in reading list | Solver workspaces define thread-local solver instances with per-stage basis caches, but the exact lifecycle (creation, reuse across iterations, destruction) and the interaction with `rayon`/thread-pool patterns are not fully specified in the trait spec. The workspace is referenced by multiple specs but its own spec was not in the critical reading list.                                                                             | Include [Solver Workspaces](../architecture/solver-workspaces.md) in the critical path review. Verify that the workspace lifecycle is consistent with the threading model decision (GAP-018).                                                                                                                                                                                                                           |
| GAP-037 | High     | cobre-sddp                   | [Training Loop](../architecture/training-loop.md)                                                                                | 4.3                 | The lower bound computation states "first-stage LP objective value (the deterministic lower bound)" but the LB is described as coming from `allreduce` with `ReduceOp::Min`. If all ranks solve the same stage-1 LP (since stage 1 has a fixed initial state), the LB should be identical across ranks. Using `Min` implies ranks may have different LB values. Clarify whether each rank solves stage 1 once or per-scenario.                 | Clarify: each rank solves stage 1 for each of its assigned scenarios. The LB is the stage-1 objective (which includes the theta approximation). Since all scenarios at stage 1 share the same initial state but may differ in random seed selection, `allreduce Min` selects the minimum across all first-stage solves. Alternatively, if stage 1 is deterministic, document that only rank 0 solves it and broadcasts. |
| GAP-038 | High     | cobre-sddp                   | [Training Loop](../architecture/training-loop.md), [Convergence Monitoring](../architecture/convergence-monitoring.md)           | 4.3, 1              | The upper bound is computed as "mean total forward cost across all trajectories" but the upper bound std computation requires the raw per-scenario costs. After `allreduce Sum`, each rank has only the global sum and sum-of-squares, not individual costs. The std formula uses individual deviations. Either a `gatherv` of all costs or an online variance formula (Welford's algorithm via sum, sum-of-squares, count) must be specified. | Specify that the forward pass `allreduce` uses three values: `(sum_costs, sum_costs_squared, count)` with `ReduceOp::Sum`. Each rank computes `mean = sum/count` and `std = sqrt((sum_sq/count - mean^2) * count/(count-1))`. Document this Welford-style aggregation.                                                                                                                                                  |

## 4. Key Decisions Resolved by Stakeholder Review

The following items are explicitly NOT gaps. They represent intentional design decisions documented in the specification corpus.

**Deferred features are not gaps.** The following are deferred by design and do not block the minimal viable solver:

- Python bindings (cobre-python), TUI (cobre-tui), MCP server (cobre-mcp)
- TCP and shared-memory communication backends
- CVaR risk measure, Cyclic horizon mode, LML1 cut selection
- External and Historical sampling schemes
- CLP solver backend
- Multi-cut formulation, FPHA hyperplanes, GNL dispatch, batteries
- Non-convex simulation extensions (linearized head, unit commitment)
- Complete tree mode (DECOMP-like)
- Monte Carlo backward sampling
- State deduplication in the backward pass

**Architectural hooks for deferred features.** The trait-based architecture (RiskMeasure, CutSelectionStrategy, HorizonMode, SamplingScheme, SolverInterface, Communicator) provides extension points for all deferred features. The enum dispatch pattern (flat enum with match at call sites) is documented in the learnings and does not require breaking changes to add variants. The compile-time monomorphization pattern (SolverInterface, Communicator) similarly accommodates new backends via feature flags. These hooks are adequately specified.

**"Real crates, real boundaries" is a design constraint, not a gap.** The requirement that all 11 crate boundaries are respected (implementation ordering requirement 2) means that crate interface gaps are blockers even when the functionality they serve is deferred. This is why GAP-001 (System type), GAP-004 (StageTemplate construction), GAP-012 (load_case API), and GAP-020 (SimulationWriter) are logged as gaps despite being "obvious" implementation details.

**Stub element types.** Contracts, Pumping Stations, and Non-Controllable sources have code-path stubs in the minimal viable solver. The stubs are specified in implementation ordering section 7 and internal structures sections 7-9. No additional specification is needed for the stubs beyond the existing entity type definitions.

## 5. Known Performance Risks

| Risk                                                              | Source                                                                        | Impact                                                                                                                                                                                                                                         | Mitigation                                                                                                                                                                                                                                                              |
| ----------------------------------------------------------------- | ----------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Dominated cut detection at 7.7G FLOPs                             | [Cut Selection Trait](../architecture/cut-selection-trait.md) SS6.4           | Dominated strategy is $\mathcal{O}(\lvert\text{active cuts}\rvert \times \lvert\text{visited states}\rvert)$ per stage per check. At production scale: 15,000 cuts x 192 states x 2,080 state dims x 120 stages = 7.7 billion FLOPs per check. | Not in minimal viable (Level-1 is selected). Flag for feature-gated implementation with optional parallelization when dominated strategy is added.                                                                                                                      |
| `Result`-returning hot-path methods (`solve`, `solve_with_basis`) | [Solver Interface Trait](../architecture/solver-interface-trait.md) SS2.4     | Every LP solve returns `Result`, adding branch prediction overhead on the hot path. With millions of solves per training run, the error path cost is unknown.                                                                                  | Require error-path benchmarking during initial implementation. Measure the overhead of `Result` unwrapping vs. a panic-on-error alternative. The learnings (epic-04) flag this explicitly.                                                                              |
| LP scaling strategy unresolved                                    | [Solver Abstraction](../architecture/solver-abstraction.md) SS3               | Production-scale LPs with 8,000+ variables and accumulating cuts may exhibit poor numerical conditioning without scaling, leading to solver retries and convergence degradation.                                                               | Adopt single-phase scaling as baseline (GAP-010). Profile with production-scale test cases early.                                                                                                                                                                       |
| Cut pool memory at 28 GB per rank                                 | [Cut Management Implementation](../architecture/cut-management-impl.md) SS1.3 | The pre-allocated cut pool requires ~28 GB per MPI rank at production scale (120 stages x 15,000 cuts x 2,080 state dims x 8 bytes). On nodes with 4 ranks per NUMA domain, this totals 112 GB for cut pools alone.                            | Monitor actual memory usage during integration testing. The shared memory optimization (cut pool via `SharedRegion`) can reduce this to ~28 GB per node if adopted. Level-1 selection reduces the active cut count, but pre-allocation is based on worst-case capacity. |
| Missing baseline latency targets                                  | [Production Scale Reference](../overview/production-scale-reference.md)       | The production scale reference specifies system sizes and memory estimates but provides no wall-clock time targets (e.g., "iteration time < 30s" or "total training < 2 hours"). Without targets, performance regressions cannot be detected.  | Define baseline latency targets after the first end-to-end integration test on production-scale data. Use these as regression gates in CI.                                                                                                                              |

## 6. Summary Statistics

**By severity (3 Blockers resolved: GAP-001, GAP-002, GAP-003):**

| Severity             | Count  |
| -------------------- | ------ |
| Blocker (unresolved) | 2      |
| Blocker (resolved)   | 3      |
| High                 | 15     |
| Medium               | 13     |
| Low                  | 5      |
| **Total**            | **38** |
| **Total unresolved** | **35** |

**By crate (a gap affecting multiple crates is counted once per crate; Blocker column shows unresolved only):**

| Crate            | Blocker | High | Medium | Low | Total |
| ---------------- | ------- | ---- | ------ | --- | ----- |
| cobre-core       | 0       | 1    | 1      | 2   | 4     |
| cobre-io         | 0       | 1    | 3      | 1   | 5     |
| cobre-stochastic | 0       | 1    | 2      | 1   | 4     |
| cobre-solver     | 1       | 4    | 0      | 1   | 6     |
| cobre-sddp       | 2       | 11   | 9      | 3   | 25    |
| cobre-comm       | 0       | 0    | 0      | 2   | 2     |
| cobre-cli        | 0       | 1    | 1      | 1   | 3     |
| ferrompi         | 0       | 1    | 0      | 1   | 2     |

Note: Gap counts per crate exceed the total gap count because some gaps affect multiple crates. cobre-sddp dominates because it is the integration crate that consumes APIs from all other crates; most of its gaps are interface definitions at crate boundaries. Three resolved Blockers (GAP-001, GAP-002, GAP-003) are excluded from the Blocker and Total columns above; the rows remain in the inventory table for historical reference.

## 7. Resolution Log

| GAP ID  | Resolved Date | Plan / Epic              | Ticket     | Resolution Summary                                              |
| ------- | ------------- | ------------------------ | ---------- | --------------------------------------------------------------- |
| GAP-001 | 2026-02-26    | gap-resolution / epic-02 | ticket-004 | System struct sketch with public API in Internal Structures SS1 |
| GAP-002 | 2026-02-26    | gap-resolution / epic-02 | ticket-005 | Decommissioned = Non-existing in Internal Structures SS2        |
| GAP-003 | 2026-02-26    | gap-resolution / epic-02 | ticket-006 | rkyv serialization in Input Loading Pipeline SS6                |

## 8. Cross-References

| Target                                                                                                      | Relevance                                                                                                                                                                                        |
| ----------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| [Implementation Ordering](./implementation-ordering.md)                                                     | Defines the 8 minimal viable crates, phase structure, and trait variant selection that scope this inventory                                                                                      |
| [Cross-Reference Index](../cross-reference-index.md)                                                        | Per-crate reading lists (section 2) used to systematically identify which specs to audit for each crate                                                                                          |
| [Training Loop](../architecture/training-loop.md)                                                           | Most-connected spec; coordinates forward/backward passes across cobre-sddp, cobre-solver, cobre-stochastic, cobre-comm. Source of 10 gaps (GAP-005, 006, 008, 013, 018, 026, 030, 032, 037, 038) |
| [Solver Abstraction](../architecture/solver-abstraction.md)                                                 | Defines the LP layout convention and solver contract. Contains 2 open points (GAP-010, 011) and the cut pool design (GAP-034)                                                                    |
| [Solver Interface Trait](../architecture/solver-interface-trait.md)                                         | Formal solver trait definition. Source of GAP-009 (patch_rhs_bounds ambiguity) and performance risk (Result on hot path)                                                                         |
| [Internal Structures](../data-model/internal-structures.md)                                                 | Defines the in-memory data model consumed by all downstream crates. Source of GAP-001, 002, 012, 031                                                                                             |
| [Input Loading Pipeline](../architecture/input-loading-pipeline.md)                                         | Defines the cobre-io to cobre-core handoff. Source of GAP-003, 012, 029                                                                                                                          |
| [Scenario Generation](../architecture/scenario-generation.md)                                               | Defines the cobre-stochastic pipeline. Source of GAP-014, 022, 023                                                                                                                               |
| [Cut Management Implementation](../architecture/cut-management-impl.md)                                     | Defines the FCF runtime structure. Source of GAP-007, 024, 034                                                                                                                                   |
| [Production Scale Reference](./production-scale-reference.md)                                               | Provides system dimensions and memory estimates used to assess performance risks                                                                                                                 |
| [Configuration Reference](../configuration/configuration-reference.md)                                      | Documents all config parameters. Source of GAP-019, 027, 035                                                                                                                                     |
| [Communicator Trait](../hpc/communicator-trait.md)                                                          | Defines the cobre-comm API surface. Source of GAP-033                                                                                                                                            |
| [Backend: Ferrompi](../hpc/backend-ferrompi.md)                                                             | Defines the MPI backend. Source of GAP-017                                                                                                                                                       |
| [Convergence Monitoring](../architecture/convergence-monitoring.md)                                         | Defines stopping rule evaluation. Source of GAP-015, 038                                                                                                                                         |
| Accumulated Learnings (Epic 04)  `plans/spec-readiness/learnings/epic-04-summary.md` (outside mdBook tree) | Known issues from prior spec readiness work: dominated strategy FLOP cost, Result-returning hot-path methods, convention blockquote verification                                                 |
