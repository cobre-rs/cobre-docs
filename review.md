Overall, I liked the learnings from the plans/spec-readiness plan very much. They summarized key decision points and development approach that should be preserved across the entire ecosystem development. For me, these decisions should be not only in plan learnings files, but in the actual documentation for the cobre ecosystem somewhere, for us to use as guidelines when making actual implementation plans. Lets consider how we could do this.

Here are my considerations regarding the blocking Spec Gaps:

GAP-001: We must specify this SystemRepresentation. In the first moment, it seems that a simple struct with some vectors of system elements would suffice, but I think the actual thing is more intrincate. I've noticed that you mentioned that if would affect both cobre-core and core-sddp. In cobre-core we can have clean, beautiful data models, that are simple to understand. In cobre-sddp, which reads from cobre-core, we have to begin adapting the data structures so that we gain performance in the actual hot path of the SDDP algorithm, so we might have to sacrifice something. Lets consider this and begin desining this top-level type

GAP-002: The operative state for Decomissioned is similar to the Non-existing entities. For most entities such as buses, lines and thermals, they simply don't work anymore. For hydros, I think we don't have to worry about reservoir drainage at this moment. Since decomissioning a hydro is something we don't have experience yet, lets still consider that the hydro lifecycle is simple in both non-existent and decomissioned states, leaving the complexity for the dead-volume filling and operating.

GAP-003: I think bincode is now unmaintained. Lets stick with rkyv for now. Proceed adding the Serialize/Deserialize bounds in the necessary types as well.

GAP-004: Since a Stage is something exclusive to the SDDP algorithm, I think the cobre-sddp crate should own this struct and know how to build it. The solver should not worry about what the LP that it is solving means. Considering this, the way we build the Stage LP sould be optimized to the hot path operations of the SDDP algorithm, which are:

- Transfering state from the past LP to the next one. This involves copying storage levels and past inflows. Since they are large amounts of values (thousands in production cases), we should organize the variables such that this operation is done with a single continuous slice (ideally we should make a vector like [storage_0, storage_1, ..., storage_N, inflow_0_lag0, inflow_1_lag0, ..., inflow_N_lag0, inflow_0_lag1, ..., inflow_N_lag1, ..., inflow_1_lagL, inflow_N_lagL], and the slice is simply ignoring the last inflow lags). This may assume storing all inflow lags (up to the maximum order of PAR model) for all hydros in all stages for simplicity. Also, we should declare the constraints such that the rows that contains duals which will be used in cut computation are continuous for the same reasons. We prefer putting things that will be accessed frequently in the beginning of the arrays, to optimize indexing.

- Extracting LP results and storing them efficiently to apply again when needed (backward step, cut computation) 

- Compute cuts efficiently, store them in a nice way in the FlatBuffers so we can recover them fast and re-apply them to the LPs without losing performance in the hot path.

GAP-005: The state vectors can be considered to be this flat vector too, with each position always corresponding to the cut vector coefficient associated with that state. The most common operation for this will be the dot product between state and cut, so we should optimize for this. Extracting these vectors as clean, continuous slices from the LP are concerns for the LP modeling and are addressed. There should also be some "indexer" helper structs that we access like LP[stage_template.storage], or something in this sense, that we can use to access specific primals or duals of interest. This should be a property of the stage definition, so it is read only and shared among all threads, and equal on all ranks, since all LPs in the same stage are the same, except for the noise innovations of the scenario it is solving.
